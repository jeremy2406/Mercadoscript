import requests
import csv
import time
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import re
from collections import defaultdict

def obtener_pagina(url, timeout=60, reintentos=5):
    """Obtener contenido de una p√°gina web con reintentos agresivos"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'no-cache'
    }
    
    for intento in range(reintentos):
        try:
            print(f"Intento {intento + 1}/{reintentos} para: {url[:80]}...")
            session = requests.Session()
            response = session.get(url, headers=headers, timeout=timeout)
            response.raise_for_status()
            print(f"‚úì P√°gina obtenida (Status: {response.status_code}, Tama√±o: {len(response.text)} chars)")
            return response.text
        except requests.exceptions.Timeout:
            print(f"Timeout en intento {intento + 1}")
            if intento < reintentos - 1:
                time.sleep(10)
        except requests.exceptions.RequestException as e:
            print(f"Error en intento {intento + 1}: {e}")
            if intento < reintentos - 1:
                time.sleep(10)
        except Exception as e:
            print(f"Error inesperado en intento {intento + 1}: {e}")
            if intento < reintentos - 1:
                time.sleep(10)
    
    print(f"‚ùå FALL√ì despu√©s de {reintentos} intentos")
    return None

def es_categoria_supermercado(url, texto):
    """Determinar si es una categor√≠a espec√≠fica de productos de supermercado"""
    
    # Lista de t√©rminos que S√ç indican categor√≠as v√°lidas de SUPERMERCADO
    categorias_supermercado = [
        # Carnes y prote√≠nas
        'carne', 'res', 'pollo', 'cerdo', 'pavo', 'jam√≥n', 'salami', 'chorizo', 'mortadela',
        'pescado', 'mariscos', 'camar√≥n', 'salm√≥n', 'at√∫n', 'embutidos', 'carnicer√≠a',
        
        # L√°cteos y huevos
        'leche', 'queso', 'yogurt', 'mantequilla', 'crema', 'huevos', 'l√°cteos', 'yogur',
        
        # Frutas y vegetales
        'fruta', 'vegetal', 'verdura', 'hortalizas', 'vegetales', 'frutas',
        'manzana', 'pera', 'pl√°tano', 'banano', 'lechuga', 'tomate', 'cebolla', 
        'papa', 'yuca', 'uva', 'fresa', 'naranja', 'lim√≥n',
        
        # Panader√≠a y cereales
        'pan', 'panader√≠a', 'galleta', 'cereal', 'avena', 'arroz', 'pasta', 'harina',
        'reposter√≠a', 'panaderia', 'cereales', 'granos', 'harinas',
        
        # Bebidas
        'bebida', 'agua', 'jugo', 'refresco', 'soda', 'caf√©', 't√©', 'vino', 'cerveza',
        'whisky', 'ron', 'vodka', 'licor', 'malta', 'energizante', 'bebidas',
        'jugos', 'refrescos', 'licores', 'vinos',
        
        # Limpieza y hogar
        'limpieza', 'detergente', 'jab√≥n', 'cloro', 'desinfectante', 'papel',
        'servilleta', 'ambientador', 'hogar', 'aseo',
        
        # Cuidado personal
        'shampoo', 'acondicionador', 'crema', 'desodorante', 'pasta dental',
        'cepillo', 'pa√±al', 'toalla', 'protector', 'cuidado personal', 'higiene',
        
        # Condimentos y especias
        'sal', 'az√∫car', 'aceite', 'vinagre', 'salsa', 'condimento', 'especia',
        'mayonesa', 'mostaza', 'ketchup', 'aderezo', 'condimentos',
        
        # Conservas y enlatados
        'conserva', 'enlatado', 'mermelada', 'miel', 'conservas', 'enlatados',
        
        # Congelados
        'congelado', 'helado', 'congelados', 'helados',
        
        # Mascotas
        'gato', 'perro', 'mascota', 'alimento para mascotas', 'mascotas',
        
        # Categor√≠as generales de supermercado
        'despensa', 'abarrotes', 'comestibles', 'alimentaci√≥n', 'alimentos',
        'snacks', 'dulces', 'chocolate', 'galletas'
    ]
    
    # Lista de t√©rminos que NO son categor√≠as de supermercado
    excluir_terminos = [
        # Navegaci√≥n y UI
        'ver todo', 'ver todover todo', 'mis datos', 'mi cuenta', 'mi carrito', 'mis listas', 
        'mis ordenes', 'cerrar sesi√≥n', 'iniciar sesi√≥n', 'crear cuenta', 'nuestras tiendas',
        'pol√≠ticas de privacidad', 'retiro en tienda', 'supermercadosnacional',
        'aqu√≠', 'inicio', 'contacto', 'ayuda', 'soporte',
        
        # Otras tiendas/marcas (no supermercado)
        'cuesta libros', 'juguet√≥n', 'bebemundo', 'beb√©mundo', 'casa cuesta', 'jumbo',
        'bonos ccn', 'elasticsuite', 'trabaja con nosotros',
        
        # Promociones/ofertas generales
        'entrenamiento', 'ofertas de la semana', 'exclusivo online', 'prepara un desayuno',
        'hasta un 15 de descuento', 'ofertas quincenazo', '3x2 vinos', 'culinary tours',
        
        # URLs problem√°ticas
        'javascript:', '#', '?q=', 'search', 'buscar', 'filtro'
    ]
    
    texto_lower = texto.lower().strip()
    url_lower = url.lower()
    
    # Filtrar URLs que claramente no son categor√≠as
    if any(x in url_lower for x in ['javascript:', '#', 'mailto:', 'tel:']):
        return False
    
    # Primero verificar exclusiones
    for termino in excluir_terminos:
        if termino in texto_lower or termino in url_lower:
            return False
    
    # Filtrar textos muy cortos o muy largos
    if len(texto.strip()) < 3 or len(texto.strip()) > 60:
        return False
    
    # RELAJAR LOS FILTROS: Verificar si contiene t√©rminos espec√≠ficos de supermercado
    for termino in categorias_supermercado:
        if termino in texto_lower:
            print(f"    ‚úì Coincidencia encontrada: '{texto}' contiene '{termino}'")
            return True
    
    # Verificar patrones en la URL que indiquen categor√≠as de supermercado
    patrones_url_supermercado = [
        r'/categoria[s]?/',
        r'/departamento[s]?/',
        r'/seccion[es]?/',
        r'/(frutas?|verduras?|vegetales?|carnes?|lacteos?|bebidas?|limpieza|panaderia)',
        r'/[a-zA-Z-]+-y-[a-zA-Z-]+',  # ej: frutas-y-vegetales
    ]
    
    for patron in patrones_url_supermercado:
        if re.search(patron, url_lower):
            print(f"    ‚úì Patr√≥n URL encontrado: '{url_lower}' coincide con {patron}")
            return True
    
    # MODO DEBUG: Mostrar por qu√© se rechaza
    if len(texto.strip()) >= 3 and len(texto.strip()) <= 60:
        print(f"    ‚ùå Rechazado: '{texto}' (no coincide con t√©rminos de supermercado)")
    
    return False

def encontrar_categorias_supermercado(soup, base_url):
    """Encontrar espec√≠ficamente categor√≠as de productos de supermercado"""
    categorias_validas = set()
    
    # Buscar en TODAS las √°reas posibles, empezando con las m√°s espec√≠ficas
    areas_busqueda = [
        # Selectores espec√≠ficos comunes
        '.nav a[href]', '.navigation a[href]', '.menu a[href]', 
        '.main-menu a[href]', '.primary-menu a[href]', '.header-menu a[href]',
        '.category-menu a[href]', '.departments a[href]', '.categories a[href]',
        
        # Selectores m√°s gen√©ricos
        'nav a[href]', 'header a[href]', '.header a[href]',
        'ul li a[href]', 'ol li a[href]',
        
        # Selectores de estructura com√∫n
        '.container a[href]', '.wrapper a[href]', '.content a[href]',
        
        # Por √∫ltimo, todos los enlaces
        'a[href]'
    ]
    
    enlaces_encontrados = []
    
    # Probar cada selector y ver cu√°les funcionan
    for selector in areas_busqueda:
        try:
            elementos = soup.select(selector)
            if elementos:
                print(f"‚úì Encontrados {len(elementos)} enlaces con selector: {selector}")
                if len(elementos) > len(enlaces_encontrados):
                    enlaces_encontrados = elementos
                    if len(elementos) >= 50:  # Si encuentra muchos, usar estos
                        break
        except Exception as e:
            continue
    
    print(f"Analizando {len(enlaces_encontrados)} enlaces en total...")
    
    # Debuggear algunos enlaces para entender la estructura
    print("\nüîç MUESTRA DE ENLACES ENCONTRADOS (primeros 20):")
    for i, enlace in enumerate(enlaces_encontrados[:20]):
        href = enlace.get('href', '').strip()
        texto = enlace.get_text().strip()
        print(f"  {i+1:2d}. '{texto}' -> {href}")
    
    # Procesar todos los enlaces
    for enlace in enlaces_encontrados:
        href = enlace.get('href', '').strip()
        texto = enlace.get_text().strip()
        
        if not href or href in ['#', '/', 'javascript:void(0)']:
            continue
            
        url_completa = urljoin(base_url, href)
        
        # Aplicar filtros espec√≠ficos para supermercado
        if es_categoria_supermercado(url_completa, texto):
            categorias_validas.add((url_completa, texto))
            print(f"‚úì Categor√≠a v√°lida encontrada: '{texto}' -> {url_completa}")
    
    print(f"‚úì Total de categor√≠as de supermercado encontradas: {len(categorias_validas)}")
    return list(categorias_validas)

def buscar_productos_exhaustivo(soup):
    """Buscar productos usando TODOS los selectores posibles"""
    selectores_productos = [
        # Selectores espec√≠ficos comunes
        '.product-item', '.product', '.item-product', '.producto',
        'div[class*="product"]', 'li[class*="product"]',
        '.grid-item', '.product-card', '.item', '.card',
        '[data-product-id]', '[data-product]', '[data-item]',
        
        # Selectores de listas
        'ul.products li', 'ol.products li', '.products .item',
        '.product-list .item', '.items-list .item',
        
        # Selectores de grillas
        '.grid .item', '.row .col', '.flex-item',
        '.catalog-item', '.shop-item', '.store-item',
        
        # Selectores m√°s gen√©ricos
        'article', '.article', 'div[itemtype*="Product"]',
        '[class*="item"]', '[class*="card"]'
    ]
    
    productos_encontrados = []
    
    for selector in selectores_productos:
        try:
            items = soup.select(selector)
            if items and len(items) > len(productos_encontrados):
                productos_encontrados = items
                print(f"‚úì Mejor resultado: {len(items)} productos con selector: {selector}")
        except Exception as e:
            continue
    
    # Si no encontramos productos con selectores espec√≠ficos, buscar por patrones
    if len(productos_encontrados) < 5:
        print("Buscando productos por patrones en el HTML...")
        
        # Buscar divs que contengan informaci√≥n de precio
        divs_con_precio = soup.find_all('div', text=re.compile(r'\$|precio|price|‚Ç¨|‚Ç°|‚Çµ', re.I))
        divs_padre_precio = []
        for div in divs_con_precio:
            parent = div.parent
            if parent:
                divs_padre_precio.append(parent)
        
        if divs_padre_precio:
            productos_encontrados = divs_padre_precio
            print(f"‚úì Encontrados {len(productos_encontrados)} productos por patr√≥n de precio")
    
    return productos_encontrados

def extraer_info_producto_exhaustivo(item):
    """Extraer informaci√≥n del producto de manera exhaustiva"""
    nombre = 'Nombre no disponible'
    precio = 'Precio no disponible'
    
    # Selectores para nombres (m√°s exhaustivos)
    selectores_nombre = [
        'a.product-item-link', '.product-name a', '.product-title',
        'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
        '.name a', '.title a', 'a[title]',
        '.product-name', '.name', '.title', '.titulo',
        '[class*="name"]', '[class*="title"]', '[class*="titulo"]',
        'a', 'span.name', 'div.name', 'p.name'
    ]
    
    # Selectores para precios (m√°s exhaustivos)
    selectores_precio = [
        'span.price', '.price', '.precio', '.cost', '.amount',
        '[class*="price"]', '[class*="precio"]', '[class*="cost"]',
        'span[class*="$"]', 'div[class*="$"]',
        '.currency', '.money', '.value', '.valor'
    ]
    
    # Buscar nombre
    for selector in selectores_nombre:
        try:
            elemento = item.select_one(selector)
            if elemento:
                # Intentar obtener texto de diferentes maneras
                texto_candidatos = [
                    elemento.get_text().strip(),
                    elemento.get('title', '').strip(),
                    elemento.get('alt', '').strip(),
                    elemento.get('data-name', '').strip()
                ]
                
                for texto in texto_candidatos:
                    if texto and len(texto) > 2 and len(texto) < 200:
                        nombre = texto
                        break
                
                if nombre != 'Nombre no disponible':
                    break
        except:
            continue
    
    # Buscar precio
    for selector in selectores_precio:
        try:
            elemento = item.select_one(selector)
            if elemento:
                precio_texto = elemento.get_text().strip()
                if precio_texto and ('$' in precio_texto or '‚Ç°' in precio_texto or 
                                   re.search(r'\d+[.,]\d+', precio_texto)):
                    precio = precio_texto
                    break
        except:
            continue
    
    # Si no encontr√≥ precio, buscar n√∫meros que parezcan precios
    if precio == 'Precio no disponible':
        texto_completo = item.get_text()
        patrones_precio = [
            r'\$\s*\d+[.,]?\d*',
            r'‚Ç°\s*\d+[.,]?\d*',
            r'\d+[.,]\d+\s*‚Ç°',
            r'\d+[.,]\d+\s*\$',
            r'precio[:\s]*\d+[.,]?\d*',
            r'\d{1,6}[.,]\d{2}'
        ]
        
        for patron in patrones_precio:
            match = re.search(patron, texto_completo, re.I)
            if match:
                precio = match.group()
                break
    
    return nombre, precio

def procesar_categoria_simple(url_categoria, nombre_categoria):
    """Procesar una categor√≠a con UNA SOLA P√ÅGINA"""
    print(f"\nüìÇ PROCESANDO: {nombre_categoria}")
    print(f"URL: {url_categoria}")
    
    productos_categoria = []
    
    # Obtener solo la primera p√°gina
    html_pagina = obtener_pagina(url_categoria)
    if not html_pagina:
        print("‚ùå No se pudo obtener la p√°gina")
        return []
    
    soup = BeautifulSoup(html_pagina, 'html.parser')
    
    # Buscar productos en esta p√°gina
    items = buscar_productos_exhaustivo(soup)
    productos_en_pagina = 0
    
    if items:
        print(f"Encontrados {len(items)} productos en esta p√°gina")
        
        for item in items:
            try:
                nombre, precio = extraer_info_producto_exhaustivo(item)
                
                if nombre != 'Nombre no disponible' and len(nombre.strip()) > 2:
                    productos_categoria.append({
                        'Nombre': nombre,
                        'Precio': precio,
                        'Categor√≠a': nombre_categoria,
                        'URL_Categoria': url_categoria
                    })
                    productos_en_pagina += 1
            
            except Exception as e:
                continue
        
        print(f"‚úì {productos_en_pagina} productos v√°lidos extra√≠dos")
    else:
        print("Sin productos en esta p√°gina")
    
    print(f"‚úì TOTAL EN '{nombre_categoria}': {len(productos_categoria)} productos")
    return productos_categoria

def main():
    base_url = 'https://supermercadosnacional.com/'
    todos_productos = []
    
    print("üöÄ INICIANDO SCRAPING ESPEC√çFICO PARA SUPERMERCADO")
    print("=" * 80)
    
    # Obtener p√°gina principal
    print("Obteniendo p√°gina principal...")
    html_principal = obtener_pagina(base_url)
    
    if not html_principal:
        print("‚ùå No se pudo obtener la p√°gina principal")
        return
    
    soup_principal = BeautifulSoup(html_principal, 'html.parser')
    
    # Encontrar solo categor√≠as de supermercado
    print("\nBUSCANDO CATEGOR√çAS ESPEC√çFICAS DE SUPERMERCADO...")
    categorias_validas = encontrar_categorias_supermercado(soup_principal, base_url)
    
    if not categorias_validas:
        print("‚ùå No se encontraron categor√≠as de supermercado v√°lidas")
        print("Mostrando algunos enlaces encontrados para depuraci√≥n:")
        enlaces_debug = soup_principal.find_all('a', href=True)[:20]
        for enlace in enlaces_debug:
            texto = enlace.get_text().strip()
            href = enlace.get('href', '')
            if texto and href:
                print(f"  - {texto} -> {href}")
        return
    
    print(f"\nüìä ENCONTRADAS {len(categorias_validas)} CATEGOR√çAS DE SUPERMERCADO")
    print("\nLista de categor√≠as a procesar:")
    for i, (url, nombre) in enumerate(categorias_validas, 1):
        print(f"  {i:3d}. {nombre}")
    
    # Procesar cada categor√≠a (solo primera p√°gina)
    contador_categorias = 0
    contador_productos_total = 0
    
    for i, (url_categoria, nombre_categoria) in enumerate(categorias_validas, 1):
        try:
            print(f"\n{'='*15} CATEGOR√çA {i}/{len(categorias_validas)} {'='*15}")
            
            productos_categoria = procesar_categoria_simple(url_categoria, nombre_categoria)
            
            if productos_categoria:
                todos_productos.extend(productos_categoria)
                contador_categorias += 1
                contador_productos_total += len(productos_categoria)
                
                print(f"‚úì Completada: {len(productos_categoria)} productos")
            else:
                print(f"Sin productos en: {nombre_categoria}")
            
            # Guardar progreso cada 10 categor√≠as
            if i % 10 == 0:
                timestamp = int(time.time())
                archivo_progreso = f'progreso_inventario_{timestamp}.csv'
                
                with open(archivo_progreso, mode='w', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=['Nombre', 'Precio', 'Categor√≠a', 'URL_Categoria'])
                    writer.writeheader()
                    for producto in todos_productos:
                        writer.writerow(producto)
                
                print(f"üíæ PROGRESO GUARDADO: {len(todos_productos)} productos")
            
            # Pausa entre categor√≠as
            time.sleep(3)
                
        except Exception as e:
            print(f"‚ùå Error procesando {nombre_categoria}: {e}")
            continue
    
    # Guardar resultados finales
    if todos_productos:
        timestamp = int(time.time())
        nombre_archivo = f'inventario_nacional_supermercado_{timestamp}.csv'
        
        with open(nombre_archivo, mode='w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['Nombre', 'Precio', 'Categor√≠a', 'URL_Categoria'])
            writer.writeheader()
            for producto in todos_productos:
                writer.writerow(producto)
        
        print(f'\nüéâ SCRAPING COMPLETADO')
        print(f'‚úì {len(todos_productos)} productos guardados en {nombre_archivo}')
        
        # Resumen por categor√≠a
        categorias_resumen = defaultdict(int)
        for producto in todos_productos:
            categorias_resumen[producto['Categor√≠a']] += 1
        
        print(f"\nüìä RESUMEN FINAL:")
        print(f"   Categor√≠as procesadas: {contador_categorias}")
        print(f"   Total de productos: {len(todos_productos)}")
        print(f"\nProductos por categor√≠a:")
        
        for categoria, cantidad in sorted(categorias_resumen.items(), key=lambda x: x[1], reverse=True):
            print(f"   {categoria}: {cantidad} productos")
            
    else:
        print('\n‚ùó No se extrajo ning√∫n producto.')
        print('\nüîç SUGERENCIAS PARA DEPURACI√ìN:')
        print('   1. Verificar que el sitio web tenga un men√∫ de categor√≠as visible')
        print('   2. Inspeccionar manualmente el HTML del sitio para identificar selectores')
        print('   3. Considerar que el sitio podr√≠a requerir JavaScript para cargar categor√≠as')

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n‚èπ Script interrumpido por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error no controlado: {e}")
        import traceback
        print(traceback.format_exc())